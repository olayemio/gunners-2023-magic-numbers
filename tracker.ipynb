{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5ee6f39-23c2-422d-b729-7d4211ac5473",
   "metadata": {},
   "source": [
    "# Import structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06893b0-3dff-4073-bfef-6cf5065072e9",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44234dce-f597-4aa4-b3ac-b041b7d9acef",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80fdcd4c-82cf-4f1a-a3e4-ce2c1d90cc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import itertools\n",
    "import heapq\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b3dc53-511c-4dfd-951a-573152075cb1",
   "metadata": {},
   "source": [
    "Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8c3988c-906e-4fb4-b000-689a5619d7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URLs\n",
    "url_table = \"https://www.premierleague.com/tables\"\n",
    "url_fixtures = \"https://www.premierleague.com/fixtures\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bd077d8-463c-4193-bd98-6d76a6e9fe28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Team abbreviations\n",
    "dct_nicknames_to_abbr = {\n",
    "    'Arsenal':\"ARS\",\n",
    "    'Aston Villa':\"AVL\",\n",
    " 'Bournemouth':\"BOU\",\n",
    " 'Brentford':\"BRE\",\n",
    " 'Brighton':\"BHA\",\n",
    " 'Chelsea':\"CHE\",\n",
    " 'Crystal Palace':\"CRY\",\n",
    " 'Everton':\"EVE\",\n",
    " 'Fulham':\"FUL\",\n",
    " 'Leeds':\"LEE\",\n",
    " 'Leicester': \"LEI\",\n",
    " 'Liverpool': \"LIV\",\n",
    " 'Man City': \"MCI\",\n",
    " 'Man Utd': \"MUN\",\n",
    " 'Newcastle': \"NEW\",\n",
    " \"Nott'm Forest\": \"NFO\",\n",
    " 'Southampton': \"SOU\",\n",
    " 'Spurs': \"TOT\",\n",
    " 'West Ham': \"WHU\",\n",
    " 'Wolves': \"WOL\"\n",
    "                        }\n",
    "\n",
    "# My team\n",
    "my_team = \"ARS\"\n",
    "my_team_points = 0\n",
    "desired_positions = [1, 4, 17]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9cd213-e58b-4a27-abdb-100ee995cb68",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Download the website data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59555eb1-1a07-47e7-8697-c95a2de27931",
   "metadata": {},
   "source": [
    "Create the Google Chrome driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a633c1b-a63d-4596-b1b3-edec30cff54d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method WebDriver.minimize_window of <selenium.webdriver.chrome.webdriver.WebDriver (session=\"3d86744b86d576f554ae5584f40ffd8f\")>>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameter includes the path of the webdriver.\n",
    "driver = webdriver.Chrome('chromedriver') \n",
    "# Minimize\n",
    "driver.minimize_window"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38efc5db-c1ce-4de8-bdf6-017a4b917de9",
   "metadata": {},
   "source": [
    "Access the first website and grab the EPL table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a883fb3-fa41-4a31-b574-dab8112d8494",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url_table)\n",
    "\n",
    "# this is just to ensure that the page is loaded\n",
    "time.sleep(5)\n",
    "\n",
    "# Accept All Cookies pop-up\n",
    "wait = WebDriverWait(driver, 5)\n",
    "\n",
    "try:\n",
    "    wait.until(EC.element_to_be_clickable((By.XPATH, '//button[normalize-space()=\"Accept All Cookies\"]'))).click()\n",
    "except TimeoutException:\n",
    "    pass\n",
    "\n",
    "# this renders the JS code and stores all of the information in static HTML code.\n",
    "html_table = driver.page_source"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1273b6e5-4cf1-4aa2-8bce-fe4cb2b895ec",
   "metadata": {},
   "source": [
    "Access the second website and grab the fixtures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "548b072e-ca86-4892-8e05-707ed05edafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the fixtures page\n",
    "driver.get(url_fixtures)\n",
    "\n",
    "# this is just to ensure that the page is loaded\n",
    "time.sleep(5)\n",
    "\n",
    "# Scroll to end of page\n",
    "SCROLL_PAUSE_TIME = 2\n",
    "\n",
    "# Get scroll height\n",
    "last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "while True:\n",
    "    # Scroll down to bottom\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "    # Wait to load page\n",
    "    time.sleep(SCROLL_PAUSE_TIME)\n",
    "\n",
    "    # Calculate new scroll height and compare with last scroll height\n",
    "    new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    if new_height == last_height:\n",
    "        break\n",
    "    last_height = new_height\n",
    "\n",
    "# this renders the JS code and stores all of the information in static HTML code.\n",
    "    \n",
    "html_fixtures = driver.page_source"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956d6cc0-fa11-411f-b79e-24ea10486c20",
   "metadata": {},
   "source": [
    "Close the browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63c0cc69-cb51-4e61-a94e-82e195cced18",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close() # closing the webdriver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b41ca05-4001-4472-992a-b9be51f50f75",
   "metadata": {},
   "source": [
    "## Parse the web pages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb56d7f-d9f4-4854-a777-b9140b02dae3",
   "metadata": {},
   "source": [
    "### Parse information from the EPL table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85452936-1a3a-4228-9c6e-1661dce3b13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make soup from the HTML of the League Table\n",
    "soup_table = BeautifulSoup(html_table, \"html.parser\")\n",
    "\n",
    "# Teamographic information\n",
    "dct_table = {'team':[], 'badge': [], 'long_name': [], 'points': [], 'played': []}\n",
    "\n",
    "# Grab all the rows\n",
    "rows = soup_table.find(\"tbody\", {\"class\": \"isPL\"}).find_all(\"tr\", {\"data-filtered-table-row-expander\": None})\n",
    "\n",
    "# Loop through each row to grab name and the points\n",
    "for row in rows:\n",
    "    # Grab the cell with the club badge and name\n",
    "    team = row.find(\"td\", {\"class\": \"team\"})\n",
    "    # Grab the badge\n",
    "    badge = team.find(\"img\", {\"class\": \"badge-image\"})['src']\n",
    "    # Grab the long name\n",
    "    long_name = team.find(\"span\", {\"class\": \"long\"}).text\n",
    "    # Grab the short name\n",
    "    short_name = team.find(\"span\", {\"class\": \"short\"}).text\n",
    "    # Grab the current points\n",
    "    points = int(row.find(\"td\", {\"class\": \"points\"}).text)\n",
    "    # Calculate max points\n",
    "    played = int(row.findAll(\"td\")[3].text)\n",
    "    \n",
    "    # Add the team details to the dictionary\n",
    "    dct_table['team'].append(short_name)\n",
    "    dct_table['badge'].append(badge)\n",
    "    dct_table['long_name'].append(long_name)\n",
    "    dct_table['points'].append(points)\n",
    "    dct_table['played'].append(played)\n",
    "    \n",
    "    if short_name == my_team:\n",
    "        my_team_points = points\n",
    "    \n",
    "    \n",
    "# Store the dictionary as a pandas DataFrame\n",
    "df_table = pd.DataFrame.from_dict(dct_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff600e4d-7807-4ae8-bfab-bc3783283148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the max points\n",
    "df_table['max_points'] = df_table['points'] + (38 - df_table['played'])*3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8f5744-dfad-4dbd-a47c-edb62ccc9c0d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Parse information from the fixtures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7110d61a-67a7-4d9d-9ae1-252d59710c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make soup from the HTML of the fixtures\n",
    "soup_fixtures = BeautifulSoup(html_fixtures, \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9aad8c-7c8c-4962-8634-baec0aad81b4",
   "metadata": {},
   "source": [
    "Grab the dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b8d8c5b-05a9-4e61-b9c8-07dca2ed88fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "elm_dates = soup_fixtures.find_all(\"div\", class_='fixtures__matches-list')\n",
    "match_dates = []\n",
    "for elm_date in elm_dates:\n",
    "    date_attr = elm_date.attrs[\"data-competition-matches-list\"]\n",
    "    date = datetime.strptime(date_attr, \"%A %d %B %Y\") if date_attr != \"Date To Be Confirmed\" else \"\"\n",
    "    match_dates.append(date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9675f4-dc4b-4992-93bd-e21c4e418713",
   "metadata": {},
   "source": [
    "Grab the fixtures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c44620f-7802-4fc3-87db-8a6ccdfbfd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "elm_matches = soup_fixtures.find_all(\"li\", class_=\"matchFixtureContainer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb3c5be-b16f-4aba-9d8a-bff3c3724eb2",
   "metadata": {},
   "source": [
    "Simulate the fixtures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcdae75-90a6-4ab9-bfda-5ae4458e4377",
   "metadata": {},
   "source": [
    "Grab the table containing all the teams and their points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b88ef0a6-d6eb-4cb6-a5b8-8c5da0e4b6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = []\n",
    "for elm_match in elm_matches:\n",
    "\n",
    "    # Get the teams\n",
    "    home = dct_nicknames_to_abbr[elm_match['data-home']]\n",
    "    away = dct_nicknames_to_abbr[elm_match['data-away']]\n",
    "\n",
    "    # Create the points possibilities\n",
    "    match = {\"home\":home, \"away\":away}\n",
    "\n",
    "    # Append\n",
    "    matches.append(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f7382e3-2729-44a1-a068-6d5f7b626d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ordinal(n):\n",
    "    '''\n",
    "    Convert an integer into its ordinal representation::\n",
    "\n",
    "        make_ordinal(0)   => '0th'\n",
    "        make_ordinal(3)   => '3rd'\n",
    "        make_ordinal(122) => '122nd'\n",
    "        make_ordinal(213) => '213th'\n",
    "    '''\n",
    "    n = int(n)\n",
    "    if 11 <= (n % 100) <= 13:\n",
    "        suffix = 'th'\n",
    "    else:\n",
    "        suffix = ['th', 'st', 'nd', 'rd', 'th'][min(n % 10, 4)]\n",
    "    return str(n) + suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d505cbe-e06d-4bf5-add6-4ddf0ac09880",
   "metadata": {},
   "outputs": [],
   "source": [
    "def oxford_comma(items):\n",
    "    length = len(items)\n",
    "    if length == 1:\n",
    "        return items[0]\n",
    "    if length == 2:\n",
    "        return '{} and {}'.format(*items)\n",
    "    return '{}, and {}'.format(', '.join(items[:-1]), items[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33b60950-a392-4381-8fa3-1eda3d747af9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Position: \t\t1\n",
      "\tMagic number: \t47\n",
      "\tTeams: \t\tMCI\n",
      "\tMatches: \t0\n",
      "\n",
      "Position: \t\t4\n",
      "\tMagic number: \t38\n",
      "\tTeams: \t\tMCI, MUN, NEW, and TOT\n",
      "\tMatches: \t0\n",
      "\n",
      "Position: \t\t17\n",
      "\tMagic number: \t20\n",
      "\tTeams: \t\tLEI, WOL, WHU, LEE, and EVE\n",
      "\tMatches: \t1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def magic_number(my_team, positions, current_table, matches_to_play):\n",
    "    \n",
    "    def magic_number_helper(pos, current_table, matches):# Ge\n",
    "        # Get the points total of the team right outside that position\n",
    "        first_out = max_table.loc[pos, 'max_points']\n",
    "\n",
    "        # Get all the team above the threshold, but cap it at the first 6 teams above the threshold\n",
    "        filter_my_team = max_table['team']!=my_team\n",
    "        filter_eq_threshold = max_table['max_points'] == first_out\n",
    "        filter_gt_threshold = max_table['max_points'] > first_out\n",
    "        filter_index = max_table.index.isin(range(max(0,pos-4), pos))\n",
    "        filtered_table = max_table[filter_my_team & (filter_eq_threshold | (filter_gt_threshold & filter_index))].copy()\n",
    "        \n",
    "        # Get all the matches by the teams in question\n",
    "        relevant_teams = list(filtered_table['team'])\n",
    "        relevant_matches = []\n",
    "        for match in matches:\n",
    "            home = match['home']\n",
    "            away = match['away']\n",
    "            if home in relevant_teams and away in relevant_teams:\n",
    "                possibilities = [{home: -3, away:0}, {home: -2, away:-2},{home:0, away:-3}]\n",
    "                relevant_matches.append(possibilities)    \n",
    "    \n",
    "        simulation_points_min = []\n",
    "        # Iterate through all simulation combinations so that we can adjust the actual probable ending tables\n",
    "        for simulation in itertools.product(*relevant_matches):\n",
    "            relevant_table_simulated = dict(filtered_table[['team', 'max_points']].values)\n",
    "            for simulated_match in simulation:\n",
    "                for team, value in simulated_match.items():\n",
    "                    # Update the adjustment\n",
    "                    relevant_table_simulated[team] += value\n",
    "            simulated_first_out = heapq.nlargest(pos, relevant_table_simulated.values())[-1]\n",
    "            simulation_points_min.append(simulated_first_out)\n",
    "        return max(simulation_points_min)+1, relevant_matches, relevant_teams\n",
    "        \n",
    "    # Sort the table\n",
    "    max_table = current_table.copy()\n",
    "    max_table.sort_values(by=['max_points'])\n",
    "    \n",
    "    for pos in positions:\n",
    "        magic_number, relevant_matches, teams = magic_number_helper(pos, max_table, matches)\n",
    "        \n",
    "        print(f\"Position: \\t\\t{pos}\")\n",
    "        print(f\"\\tMagic number: \\t{magic_number - my_team_points}\")\n",
    "        print(f\"\\tTeams: \\t\\t{oxford_comma(teams)}\")\n",
    "        print(f\"\\tMatches: \\t{len(relevant_matches)}\")\n",
    "        print(\"\")\n",
    "              \n",
    "\n",
    "magic_number(\"ARS\", [1,4,17], df_table, matches)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
